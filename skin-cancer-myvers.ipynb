{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1193409,"sourceType":"datasetVersion","datasetId":679322}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/annamalkova88/skin-cancer-myvers?scriptVersionId=152104724\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick navigation</center></h2>\n\n* [0. Installation of libraries](#0)\n* [1. Basic Data Overview](#1)\n* [2. Transformation of data](#2)\n* [3. Convolutional networks](#3)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"0\"></a>\n<h2 style='background:orange; border:0; color:white'><center>0. Installation of libraries</center><h2>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt\nimport imageio\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nfrom skimage import io \nfrom PIL import Image\n\nfrom sklearn.preprocessing import LabelBinarizer, StandardScaler,LabelEncoder\nfrom sklearn import preprocessing \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.linear_model import LinearRegression,LogisticRegression\nfrom sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D,Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization,Concatenate\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam, Adamax\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Sequential\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:00.299561Z","iopub.execute_input":"2023-11-21T13:06:00.300648Z","iopub.status.idle":"2023-11-21T13:06:17.038171Z","shell.execute_reply.started":"2023-11-21T13:06:00.300605Z","shell.execute_reply":"2023-11-21T13:06:17.036994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:orange; border:0; color:white'><center>1. Basic Data Overview</center><h2>","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/isic-2019/ISIC_2019_Training_Metadata.csv')\ndisplay(train_df.head(),\n        train_df.info(), \n        'Missing values',\n        train_df.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:17.040303Z","iopub.execute_input":"2023-11-21T13:06:17.041186Z","iopub.status.idle":"2023-11-21T13:06:17.188304Z","shell.execute_reply.started":"2023-11-21T13:06:17.041131Z","shell.execute_reply":"2023-11-21T13:06:17.187089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y = pd.read_csv('/kaggle/input/isic-2019/ISIC_2019_Training_GroundTruth.csv')\ndisplay(train_y.head(),\n        train_y.info(), \n        'Missing values',\n        train_y.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:17.189441Z","iopub.execute_input":"2023-11-21T13:06:17.190579Z","iopub.status.idle":"2023-11-21T13:06:17.301516Z","shell.execute_reply.started":"2023-11-21T13:06:17.19048Z","shell.execute_reply":"2023-11-21T13:06:17.300336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_df.merge(train_y, on='image', how='outer')\ndisplay(train.head(),\n        train.info(), \n        'Missing values',\n        train.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:17.305492Z","iopub.execute_input":"2023-11-21T13:06:17.306178Z","iopub.status.idle":"2023-11-21T13:06:17.385943Z","shell.execute_reply.started":"2023-11-21T13:06:17.306113Z","shell.execute_reply":"2023-11-21T13:06:17.384829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Melanoma\n\nMelanocytic nevus\n\nBasal cell carcinoma\n\nActinic keratosis\n\nBenign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis)\n\nDermatofibroma\n\nVascular lesion\n\nSquamous cell carcinoma\n\nUknown","metadata":{}},{"cell_type":"code","source":"cols = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\ntrain['cancer'] = ''\n\nfor i in range(train.shape[0]):\n    for el in cols:\n        if train.loc[i, el] == 1:\n            train.loc[i, 'cancer'] = el\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:17.38855Z","iopub.execute_input":"2023-11-21T13:06:17.388984Z","iopub.status.idle":"2023-11-21T13:06:28.100554Z","shell.execute_reply.started":"2023-11-21T13:06:17.388954Z","shell.execute_reply":"2023-11-21T13:06:28.099496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(train, names='cancer', title='Distribution of histological types')\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:28.101878Z","iopub.execute_input":"2023-11-21T13:06:28.102275Z","iopub.status.idle":"2023-11-21T13:06:30.074866Z","shell.execute_reply.started":"2023-11-21T13:06:28.102242Z","shell.execute_reply":"2023-11-21T13:06:30.073975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Its better to exclude samples of the rarest types:\n\nAK,SCC,VASC, DF","metadata":{}},{"cell_type":"code","source":"fig = px.pie(train, names='anatom_site_general', title='Distribution of histological types')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:30.076354Z","iopub.execute_input":"2023-11-21T13:06:30.076707Z","iopub.status.idle":"2023-11-21T13:06:30.196911Z","shell.execute_reply.started":"2023-11-21T13:06:30.076676Z","shell.execute_reply":"2023-11-21T13:06:30.195575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Its better to exclude the rarest anatomic sides:\n\npalms/soles\n\noral/genital\n\nlateral torso","metadata":{}},{"cell_type":"code","source":"cols = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\nfig = make_subplots(rows=3, cols=3, subplot_titles=cols)\nfor i, el in enumerate(cols, 1):\n    df_filtered = train[train['cancer'] == el]\n    hist = px.histogram(df_filtered, x='age_approx', nbins=20, title=el)\n    fig.add_trace(hist['data'][0], row=(i - 1) // 3 + 1, col=(i - 1) % 3 + 1)\n\nfig.update_layout(height=600, width=800, showlegend=False, title_text='Age Histograms for Each Cancer Type')\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:30.198905Z","iopub.execute_input":"2023-11-21T13:06:30.199367Z","iopub.status.idle":"2023-11-21T13:06:30.814126Z","shell.execute_reply.started":"2023-11-21T13:06:30.199322Z","shell.execute_reply":"2023-11-21T13:06:30.812988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=3, cols=3, subplot_titles=cols)\nfor i, el in enumerate(cols, 1):\n    df_filtered = train[train['cancer'] == el]\n    bar_chart = px.bar(df_filtered, x='anatom_site_general', title=el)\n    \n    bar_chart.update_layout(xaxis=dict(tickangle=45, tickmode='array', tickvals=list(range(len(df_filtered['anatom_site_general'])))))\n    color = px.colors.qualitative.Set1[i - 1]\n    \n    bar_trace = bar_chart['data'][0]\n    bar_trace['marker']['color'] = color\n    fig.add_trace(bar_trace, row=(i - 1) // 3 + 1, col=(i - 1) % 3 + 1)\n\nfig.update_layout(height=1000, width=800, showlegend=False, title_text='Anatomic location for Each Cancer Type')\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:30.815717Z","iopub.execute_input":"2023-11-21T13:06:30.816077Z","iopub.status.idle":"2023-11-21T13:06:31.525881Z","shell.execute_reply.started":"2023-11-21T13:06:30.816045Z","shell.execute_reply":"2023-11-21T13:06:31.524819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\nfig = make_subplots(\n    rows=3, cols=3,\n    vertical_spacing=0.09,\n    specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"},{\"type\": \"pie\"}],\n           [{\"type\": \"pie\"}, {\"type\": \"pie\"},{\"type\": \"pie\"}],\n           [{\"type\": \"pie\"}, {\"type\": \"pie\"},{\"type\": \"pie\"}]\n          ],\n    subplot_titles=cols\n)\n\nfor i, el in enumerate(cols, 1):\n    df_filtered = train[train['cancer'] == el]\n    \n    # Calculate row and col for each subplot\n    row = (i - 1) // 3 + 1\n    col = (i - 1) % 3 + 1\n\n    fig.add_trace(\n        go.Pie(\n            values=df_filtered.sex.value_counts().values,\n            labels=['<b>Female<b>', '<b>Male<b>', '<b>None<b>'],\n            hole=0.3, pull=[0, 0.08, 0.3],\n            marker_colors=['pink', 'lightblue', 'lightgreen'],\n            textposition='inside'\n        ),\n        row=row, col=col\n    )\n\nfig.update_layout(\n    height=500,\n    showlegend=True,\n    title_text=\"<b>Sex distribution for cancer types<b>\",\n)\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:31.527674Z","iopub.execute_input":"2023-11-21T13:06:31.528443Z","iopub.status.idle":"2023-11-21T13:06:31.636482Z","shell.execute_reply.started":"2023-11-21T13:06:31.528401Z","shell.execute_reply":"2023-11-21T13:06:31.635064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There is no data for unknown - delete this column\ntrain_known = train.drop('UNK', axis=1)\ntrain_known.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:31.637888Z","iopub.execute_input":"2023-11-21T13:06:31.638646Z","iopub.status.idle":"2023-11-21T13:06:31.662016Z","shell.execute_reply.started":"2023-11-21T13:06:31.638611Z","shell.execute_reply":"2023-11-21T13:06:31.660866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndirectory = '/kaggle/input/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input'\n\n# Dictionary to store file paths\nfile_paths = {}\n\n# Iterate over files in the directory\nfor root, _, files in os.walk(directory):\n    for filename in files:\n        if filename.endswith('.jpg'):\n            path = os.path.join(root, filename)\n            file_paths[filename] = path\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:31.663259Z","iopub.execute_input":"2023-11-21T13:06:31.663579Z","iopub.status.idle":"2023-11-21T13:06:53.450759Z","shell.execute_reply.started":"2023-11-21T13:06:31.663554Z","shell.execute_reply":"2023-11-21T13:06:53.449567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_known['image'] = train_known['image'].apply(lambda x: x+'.jpg')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:53.452089Z","iopub.execute_input":"2023-11-21T13:06:53.452468Z","iopub.status.idle":"2023-11-21T13:06:53.469394Z","shell.execute_reply.started":"2023-11-21T13:06:53.452439Z","shell.execute_reply":"2023-11-21T13:06:53.468482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_known['path'] = train_known['image'].map(file_paths)\n\ntrain_known.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:53.473937Z","iopub.execute_input":"2023-11-21T13:06:53.475091Z","iopub.status.idle":"2023-11-21T13:06:53.527871Z","shell.execute_reply.started":"2023-11-21T13:06:53.475052Z","shell.execute_reply":"2023-11-21T13:06:53.526717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.image as mpimg\n\nlabels = train_known['cancer'].unique()\nimage_paths = []\n\nfor label in labels:\n    path = train_known[train_known['cancer'] == label].sample(n=1, random_state=42)['path'].values[0]\n    image_paths.append(path)\nfig, axes = plt.subplots(1, len(image_paths), figsize=(20, 5))\n\nfor i, path in enumerate(image_paths):\n    img = mpimg.imread(path)\n    axes[i].imshow(img)\n    axes[i].set_title(labels[i])\n    axes[i].axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:53.529529Z","iopub.execute_input":"2023-11-21T13:06:53.530219Z","iopub.status.idle":"2023-11-21T13:06:55.697301Z","shell.execute_reply.started":"2023-11-21T13:06:53.530147Z","shell.execute_reply":"2023-11-21T13:06:55.696286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Your existing code to get image paths\nimport pandas as pd\n\nanatom_site_counts = train_known['anatom_site_general'].value_counts()\nlabels = anatom_site_counts.index\n\n# Sort the labels based on their counts\nlabels = sorted(labels, key=lambda x: anatom_site_counts[x], reverse=True)\n\nimage_paths = []\n\nfor label in labels:\n    df_label = train_known[train_known['anatom_site_general'] == label]\n    \n    if not df_label.empty:\n        # Sample one image for each label\n        path = df_label.sample(n=1, random_state=42)['path'].values[0]\n        image_paths.append(path)\n\nimage_paths","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:14:55.413938Z","iopub.execute_input":"2023-11-21T14:14:55.41448Z","iopub.status.idle":"2023-11-21T14:14:55.46345Z","shell.execute_reply.started":"2023-11-21T14:14:55.41443Z","shell.execute_reply":"2023-11-21T14:14:55.462624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib.image as mpimg\nimport plotly.express as px\n\nfig = plt.figure(figsize=(20, 10))\ngs = gridspec.GridSpec(2, len(image_paths), height_ratios=[2, 1])\n\n# Display images in the upper part\nfor i, path in enumerate(image_paths):\n    img = mpimg.imread(path)\n    ax = plt.subplot(gs[0, i])\n    ax.imshow(img)\n    ax.set_title(labels[i])\n    ax.axis('off')\n\n# Create a bar chart in the lower part\nax = plt.subplot(gs[1, :])\n\nax.bar(anatom_site_counts.index, anatom_site_counts.values)\nax.set_title('Bar Chart')\nax.set_xlabel('Anatom Site General')\nax.set_ylabel('Count')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:15:08.360648Z","iopub.execute_input":"2023-11-21T14:15:08.361457Z","iopub.status.idle":"2023-11-21T14:15:10.325663Z","shell.execute_reply.started":"2023-11-21T14:15:08.361406Z","shell.execute_reply":"2023-11-21T14:15:10.324551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:orange; border:0; color:white'><center>3. EDA</center><h2>","metadata":{}},{"cell_type":"code","source":"train_exp = train_known.copy()\ntrain_exp.dropna(axis=0, inplace=True)\ntrain_exp.reset_index()\n#Create new feature - lesion\ntrain_exp['lesion'] = train_exp['lesion_id'].apply(lambda x: str(x).split('_')[0] if isinstance(x, str) else '')\ntrain_exp = train_exp.drop('lesion_id', axis=1)\ntrain_exp.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.163986Z","iopub.status.idle":"2023-11-21T13:06:59.164484Z","shell.execute_reply.started":"2023-11-21T13:06:59.164257Z","shell.execute_reply":"2023-11-21T13:06:59.16428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#delete the rarest h.types\nhist = ['AK','SCC','VASC', 'DF']\ntrain_exp1 = train_exp[~train_exp['cancer'].isin(hist)]\n\n#delete the rarest sides\nsides=['palms/soles','oral/genital','lateral torso']\ntrain_exp2 = train_exp1[~train_exp1['anatom_site_general'].isin(sides)]\ndisplay(train_exp2.cancer.value_counts(),\n        \n        train_exp2['anatom_site_general'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.165917Z","iopub.status.idle":"2023-11-21T13:06:59.166359Z","shell.execute_reply.started":"2023-11-21T13:06:59.16614Z","shell.execute_reply":"2023-11-21T13:06:59.166177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_coded = train_exp2.copy()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.167584Z","iopub.status.idle":"2023-11-21T13:06:59.167989Z","shell.execute_reply.started":"2023-11-21T13:06:59.167795Z","shell.execute_reply":"2023-11-21T13:06:59.167813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Coding categorical features\ncoder = preprocessing.LabelEncoder()\ntrain_coded['lesion']= coder.fit_transform(train_coded['lesion'])\n\ntransformer = preprocessing.LabelBinarizer()\ntrain_coded['sex'] = transformer.fit_transform(train_coded['sex'])\n\ntrain_coded.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.169871Z","iopub.status.idle":"2023-11-21T13:06:59.17069Z","shell.execute_reply.started":"2023-11-21T13:06:59.170485Z","shell.execute_reply":"2023-11-21T13:06:59.170506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scaling numeric features\nscaler = StandardScaler()\ncols=['age_approx','lesion']\ntrain_coded[cols] = scaler.fit_transform(train_coded[cols])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.172134Z","iopub.status.idle":"2023-11-21T13:06:59.172597Z","shell.execute_reply.started":"2023-11-21T13:06:59.172396Z","shell.execute_reply":"2023-11-21T13:06:59.172417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_coded.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.174086Z","iopub.status.idle":"2023-11-21T13:06:59.174828Z","shell.execute_reply.started":"2023-11-21T13:06:59.174632Z","shell.execute_reply":"2023-11-21T13:06:59.174652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:orange; border:0; color:white'><center>3. Transformation of images</center><h2>","metadata":{}},{"cell_type":"code","source":"import cv2\noutput_folder = '/kaggle/working/train_small/'\nos.makedirs(output_folder, exist_ok=True)\ntrain_coded.reset_index(inplace=True)\nfor i in range(train_coded.shape[0]):\n    input_path = train_coded.loc[i, 'path']\n    image = cv2.imread(input_path)\n    height, width, _ = image.shape\n    new_width = int(width/2)  # specify the new width\n    new_height = int(height * (new_width / width))  # calculate the new height to maintain the aspect ratio\n    resized_img = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n    output_path = os.path.join(output_folder, train_coded.loc[i, 'image'])\n    cv2.imwrite(output_path, resized_img)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.175979Z","iopub.status.idle":"2023-11-21T13:06:59.176778Z","shell.execute_reply.started":"2023-11-21T13:06:59.176567Z","shell.execute_reply":"2023-11-21T13:06:59.176589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_small=train_coded.copy()\nfile_paths = {}\nfor root, _, files in os.walk('/kaggle/working/train_small/'):\n    for filename in files:\n        path = os.path.join(root, filename)  \n        file_paths[filename]=path\n        \ntrain_small['path'] = train_small['image'].map(file_paths)\ntrain_small.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.178369Z","iopub.status.idle":"2023-11-21T13:06:59.179034Z","shell.execute_reply.started":"2023-11-21T13:06:59.178822Z","shell.execute_reply":"2023-11-21T13:06:59.178844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_1000 = train_small.sample(n=1000)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.180235Z","iopub.status.idle":"2023-11-21T13:06:59.180879Z","shell.execute_reply.started":"2023-11-21T13:06:59.180685Z","shell.execute_reply":"2023-11-21T13:06:59.180705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_drop = ['image', 'cancer']\ntrain_1000.drop(cols_to_drop, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.182113Z","iopub.status.idle":"2023-11-21T13:06:59.182769Z","shell.execute_reply.started":"2023-11-21T13:06:59.182573Z","shell.execute_reply":"2023-11-21T13:06:59.182593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:orange; border:0; color:white'><center>3. Convolutional network model</center><h2>","metadata":{}},{"cell_type":"code","source":"# Separate tabular data and image paths\nX_tabular = train_1000[['sex','age_approx','lesion', 'MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']]\nX_image_paths = train_1000['path']\ny_labels = train_1000['anatom_site_general']","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.183883Z","iopub.status.idle":"2023-11-21T13:06:59.184543Z","shell.execute_reply.started":"2023-11-21T13:06:59.18435Z","shell.execute_reply":"2023-11-21T13:06:59.18437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.185637Z","iopub.status.idle":"2023-11-21T13:06:59.186289Z","shell.execute_reply.started":"2023-11-21T13:06:59.186077Z","shell.execute_reply":"2023-11-21T13:06:59.186097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 1: Load and Preprocess Images\n# Load and preprocess your images\nimage_size = (100, 100)  # Set the desired size for EfficientNet\nX_images = []  # List to store preprocessed images\n\nfor path in X_image_paths:\n    # Load image\n    img = tf.keras.preprocessing.image.load_img(path, target_size=image_size)\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    \n    # Preprocess image\n    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n    \n    X_images.append(img_array)\n\nX_images = np.array(X_images)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.18741Z","iopub.status.idle":"2023-11-21T13:06:59.188041Z","shell.execute_reply.started":"2023-11-21T13:06:59.187842Z","shell.execute_reply":"2023-11-21T13:06:59.187862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 2: Prepare Labels\n# Encode the labels\nlabel_encoder = LabelEncoder()\ny_labels_encoded = label_encoder.fit_transform(y_labels)\ny_labels_encoded = tf.keras.utils.to_categorical(y_labels_encoded)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.189167Z","iopub.status.idle":"2023-11-21T13:06:59.18979Z","shell.execute_reply.started":"2023-11-21T13:06:59.189599Z","shell.execute_reply":"2023-11-21T13:06:59.189618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 3: Split Data\n# Split your data into training and validation sets\nX_train_tabular, X_val_tabular, X_train_images, X_val_images, y_train, y_val = train_test_split(\n    X_tabular, X_images, y_labels_encoded, test_size=0.2, random_state=42\n)\ndisplay(X_train_tabular.shape, \n        X_val_tabular.shape, \n        X_train_images.shape, \n        X_val_images.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.190943Z","iopub.status.idle":"2023-11-21T13:06:59.191589Z","shell.execute_reply.started":"2023-11-21T13:06:59.1914Z","shell.execute_reply":"2023-11-21T13:06:59.191419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nimage_datagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True\n)\n\n# Create generator for image data\ntrain_image_generator = image_datagen.flow(X_train_images, \n                                           y_train, \n                                           batch_size=32, \n                                           seed=42,\n                                          shuffle=False)\nval_image_generator = image_datagen.flow(X_val_images, \n                                         y_val, \n                                         batch_size=32, \n                                         seed=42,\n                                        shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.192579Z","iopub.status.idle":"2023-11-21T13:06:59.193462Z","shell.execute_reply.started":"2023-11-21T13:06:59.193269Z","shell.execute_reply":"2023-11-21T13:06:59.193289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualization of augmented pictures\ndef plotImages(images_arr):\n    fig, axes = plt.subplots(4, 4, figsize=(10,10))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.194382Z","iopub.status.idle":"2023-11-21T13:06:59.194721Z","shell.execute_reply.started":"2023-11-21T13:06:59.194555Z","shell.execute_reply":"2023-11-21T13:06:59.19457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_training_images, _ = next(train_image_generator)\n# Plot 16 random images from training data    \nplotImages(sample_training_images[:16])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.196081Z","iopub.status.idle":"2023-11-21T13:06:59.196577Z","shell.execute_reply.started":"2023-11-21T13:06:59.196402Z","shell.execute_reply":"2023-11-21T13:06:59.196419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot for accuracy and val_loss\ndef plot_accur(history, epochs=20):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(epochs)\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.197407Z","iopub.status.idle":"2023-11-21T13:06:59.197749Z","shell.execute_reply.started":"2023-11-21T13:06:59.197581Z","shell.execute_reply":"2023-11-21T13:06:59.197597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([    \n    Conv2D(32, (3, 3), activation='relu', input_shape = (100,100,3)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    Flatten(),\n    Dense(64, activation='relu'),\n    Dense(5, activation='softmax')  # num_classes is the number of output classes\n])\nK.clear_session()\nmodel.compile(optimizer=Adamax(lr=0.0001),  #Adam(lr=x)\n              loss='categorical_crossentropy',  \n              metrics=['accuracy'])\nhistory = model.fit(\n    train_image_generator,\n    epochs=20,\n    validation_data=val_image_generator,\n)\nhistory","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.199039Z","iopub.status.idle":"2023-11-21T13:06:59.199417Z","shell.execute_reply.started":"2023-11-21T13:06:59.199237Z","shell.execute_reply":"2023-11-21T13:06:59.199253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained EfficientNetB0 model without the top (classification) layer\nbase_model = EfficientNetB7(weights=None, include_top=False, input_shape=(100, 100, 3))\nnum_classes = 5   \n\n# Add your own classification layers on top of the base model\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.7)(x)\n    \n# Output layer\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# Create the final model\nmodel = Model(inputs=base_model.input, outputs=predictions)\nK.clear_session()\n# Compile the model\nmodel.compile(optimizer=Adam(lr=0.01),  \n              loss='categorical_crossentropy',  \n              metrics=['accuracy'])\nhistory = model.fit(\n    train_image_generator,\n    epochs=20,\n    validation_data=val_image_generator,\n)\nhistory","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.200674Z","iopub.status.idle":"2023-11-21T13:06:59.201286Z","shell.execute_reply.started":"2023-11-21T13:06:59.201082Z","shell.execute_reply":"2023-11-21T13:06:59.201102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accur(history, epochs=50)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.202303Z","iopub.status.idle":"2023-11-21T13:06:59.202648Z","shell.execute_reply.started":"2023-11-21T13:06:59.202481Z","shell.execute_reply":"2023-11-21T13:06:59.202497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:orange; border:0; color:white'><center>4. Multimodal convolutional network model</center><h2>","metadata":{}},{"cell_type":"code","source":"BUFFER_SIZE = 100\nlength_t = len(y_train)\nBATCH_SIZE_tr = sorted([int(length_t/n) for n in range(1,length_t+1) \n                     if length_t % n ==0 and length_t/n<=80],reverse=True)[0] \nlength_v = len(y_val)\nBATCH_SIZE_val = sorted([int(length_v/n) for n in range(1,length_v+1) \n                     if length_v % n ==0 and length_v/n<=80],reverse=True)[0] \nprint(BATCH_SIZE_tr,\n     BATCH_SIZE_val)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.203738Z","iopub.status.idle":"2023-11-21T13:06:59.204089Z","shell.execute_reply.started":"2023-11-21T13:06:59.203912Z","shell.execute_reply":"2023-11-21T13:06:59.203927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eff_model(batch_tr=64,batch_val=32,optimizer=Adamax(learning_rate=0.0001), epochs=10):\n    BUFFER_SIZE = 100\n    batch_size=batch_tr\n    train_dataset = tf.data.Dataset.from_tensor_slices((\n        {'image_input': X_train_images, 'tabular_input': X_train_tabular},\n        y_train)).shuffle(BUFFER_SIZE).batch(batch_size)\n    \n    batch_size=batch_val\n    val_dataset = tf.data.Dataset.from_tensor_slices((\n        {'image_input': X_val_images, 'tabular_input': X_val_tabular},\n        y_val)).shuffle(BUFFER_SIZE).batch(batch_size)\n    \n    # Image Branch\n    input_shape = X_train_images[0].shape\n    image_inputs = Input(shape=input_shape, name='image_input')\n    x_image = EfficientNetB7(input_shape=input_shape, include_top=False, weights=None)(image_inputs)\n    x_image = GlobalAveragePooling2D()(x_image)\n\n    # Tabular Branch\n    tabular_inputs = Input(shape=(X_train_tabular.shape[1],), name='tabular_input')\n    x_tabular = Dense(128, activation='relu')(tabular_inputs)\n\n    # Concatenate branches\n    merged = Concatenate()([x_image, x_tabular])\n\n    # Output Layer\n    outputs = Dense(len(label_encoder.classes_), activation='softmax')(merged)\n\n    # Create the model\n    model = Model(inputs=[image_inputs, tabular_inputs], outputs=outputs)\n\n    # Compile the model\n    model.compile(optimizer=optimizer,\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'],\n                 run_eagerly=True)\n    \n    test_steps_train = int(len(train_dataset) / batch_tr)\n    test_steps_val = int(len(val_dataset) / batch_val)\n\n    history = model.fit(train_dataset,\n                        epochs=epochs,\n                        validation_data=val_dataset,\n                        steps_per_epoch=test_steps_train,\n                        validation_steps=test_steps_val)\n\n    return history\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.205068Z","iopub.status.idle":"2023-11-21T13:06:59.205428Z","shell.execute_reply.started":"2023-11-21T13:06:59.205259Z","shell.execute_reply":"2023-11-21T13:06:59.205274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.206638Z","iopub.status.idle":"2023-11-21T13:06:59.206995Z","shell.execute_reply.started":"2023-11-21T13:06:59.206816Z","shell.execute_reply":"2023-11-21T13:06:59.206832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE = 100\nBATCH_SIZE=10\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n        {'image_input': X_train_images, 'tabular_input': X_train_tabular},\n        y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n\nval_dataset = tf.data.Dataset.from_tensor_slices((\n        {'image_input': X_val_images, 'tabular_input': X_val_tabular},\n        y_val)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n    \n# Image Branch\ninput_shape = X_train_images[0].shape\nimage_inputs = Input(shape=input_shape, name='image_input')\nx_image = EfficientNetB7(input_shape=input_shape, include_top=False, weights=None)(image_inputs)\nx_image = GlobalAveragePooling2D()(x_image)\n\n# Tabular Branch\ntabular_inputs = Input(shape=(X_train_tabular.shape[1],), name='tabular_input')\nx_tabular = Dense(128, activation='relu')(tabular_inputs)\n\n    # Concatenate branches\nmerged = Concatenate()([x_image, x_tabular])\n\n    # Output Layer\noutputs = Dense(len(label_encoder.classes_), activation='softmax')(merged)\n\n    # Create the model\nmodel = Model(inputs=[image_inputs, tabular_inputs], outputs=outputs)\n\n    # Compile the model\nmodel.compile(optimizer=Adamax(learning_rate=0.001),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.208106Z","iopub.status.idle":"2023-11-21T13:06:59.208855Z","shell.execute_reply.started":"2023-11-21T13:06:59.208661Z","shell.execute_reply":"2023-11-21T13:06:59.208682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,\n                        epochs=30,\n                        validation_data=val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.21057Z","iopub.status.idle":"2023-11-21T13:06:59.210938Z","shell.execute_reply.started":"2023-11-21T13:06:59.210762Z","shell.execute_reply":"2023-11-21T13:06:59.210778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accur(history, epochs=30)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.212036Z","iopub.status.idle":"2023-11-21T13:06:59.212426Z","shell.execute_reply.started":"2023-11-21T13:06:59.212244Z","shell.execute_reply":"2023-11-21T13:06:59.212262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Concatenate, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras import regularizers\n\n# Image Branch\ninput_shape = X_train_images[0].shape\nimage_inputs = Input(shape=input_shape, name='image_input')\nx_image = EfficientNetB7(input_shape=input_shape, include_top=False, weights=None)(image_inputs)\nx_image = GlobalAveragePooling2D()(x_image)\nx_image = BatchNormalization()(x_image)\nx_image = Dropout(0.4)(x_image)\n\n# Tabular Branch\ntabular_inputs = Input(shape=(X_train_tabular.shape[1],), name='tabular_input')\nx_tabular = Dense(256, kernel_regularizer=regularizers.l2(0.016), activity_regularizer=regularizers.l1(0.006),\n                  bias_regularizer=regularizers.l1(0.006), activation='relu')(tabular_inputs)\nx_tabular = BatchNormalization()(x_tabular)\n\n# Concatenate branches\nmerged = Concatenate()([x_image, x_tabular])\n\n# Additional Dense layer with Batch Normalization and Dropout\nx = Dense(128, activation='relu')(merged)\nx = BatchNormalization()(x)\nx = Dropout(0.4)(x)\n\n# Output Layer\noutputs = Dense(len(label_encoder.classes_), activation='softmax')(x)\n\n# Create the model\nmodel = Model(inputs=[image_inputs, tabular_inputs], outputs=outputs)\n\n# Learning Rate Schedule\ndef lr_schedule(epoch):\n    lr = 0.001 * 0.9**epoch\n    return lr\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\n# Compile the model\nmodel.compile(optimizer=Adamax(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Update the model.fit() call with callbacks\nhistory = model.fit(\n    train_dataset,\n    epochs=20,\n    validation_data=val_dataset,\n    callbacks=[lr_scheduler]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.213856Z","iopub.status.idle":"2023-11-21T13:06:59.214233Z","shell.execute_reply.started":"2023-11-21T13:06:59.214047Z","shell.execute_reply":"2023-11-21T13:06:59.214063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accur(history, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.21537Z","iopub.status.idle":"2023-11-21T13:06:59.215716Z","shell.execute_reply.started":"2023-11-21T13:06:59.215546Z","shell.execute_reply":"2023-11-21T13:06:59.215562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras import regularizers\n\ndef lr_schedule(epoch, lr):\n    \"\"\"Learning Rate Schedule.\n    Adjust the learning rate based on the current epoch.\n    \"\"\"\n    if epoch < 10:\n        return 0.001\n    elif 10 <= epoch < 20:\n        return 0.0005\n    else:\n        return 0.0001\n\n# Image Branch\ninput_shape = X_train_images[0].shape\nimage_inputs = Input(shape=input_shape, name='image_input')\nx_image = EfficientNetB7(input_shape=input_shape, include_top=False, weights=None)(image_inputs)\nx_image = GlobalAveragePooling2D()(x_image)\nx_image = BatchNormalization()(x_image)\nx_image = Dropout(0.5)(x_image)  # Adjust dropout rate as needed\n\n# Tabular Branch\ntabular_inputs = Input(shape=(X_train_tabular.shape[1],), name='tabular_input')\nx_tabular = Dense(128, activation='relu')(tabular_inputs)\nx_tabular = BatchNormalization()(x_tabular)\nx_tabular = Dropout(0.2)(x_tabular)  # Adjust dropout rate as needed\n\n# Concatenate branches\nmerged = Concatenate()([x_image, x_tabular])\nmerged = BatchNormalization()(merged)\nmerged = Dropout(0.3)(merged)  # Adjust dropout rate as needed\n\n# Output Layer\noutputs = Dense(len(label_encoder.classes_), activation='softmax')(merged)\n\n# Create the model\nmodel = Model(inputs=[image_inputs, tabular_inputs], outputs=outputs)\n\n# Compile the model with learning rate schedule\nmodel.compile(optimizer=Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Define learning rate scheduler\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\n# Train the model\nhistory = model.fit(train_dataset,\n                    epochs=20,\n                    validation_data=val_dataset,\n                    callbacks=[lr_scheduler])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.217579Z","iopub.status.idle":"2023-11-21T13:06:59.217929Z","shell.execute_reply.started":"2023-11-21T13:06:59.21776Z","shell.execute_reply":"2023-11-21T13:06:59.217776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accur(history, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:06:59.218938Z","iopub.status.idle":"2023-11-21T13:06:59.219343Z","shell.execute_reply.started":"2023-11-21T13:06:59.21913Z","shell.execute_reply":"2023-11-21T13:06:59.219146Z"},"trusted":true},"execution_count":null,"outputs":[]}]}